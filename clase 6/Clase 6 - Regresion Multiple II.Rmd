---
title: "Regresión Lineal Múltiple II"
author: "Juan Barriola y Sofía Perini"
date: "10 de Octubre de 2020"
output:
  html_notebook:
    theme: spacelab
    toc: yes
    toc_float: yes
    df_print: paged
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>

## Diagnóstico y Evaluación de Modelos de Regresión Lineal Múltiple

### Dataset 

Vamos a trabajar con el subconjunto de datos que surgió del trabajo de limpieza que se hizo en la clase de regresión lineal simple, correspondiente al grupo de salarios de los data scientists/analyst, de la encuesta de sueldos en el sector de tecnología en Argenina realizada por SysArmy. El informe, realizado por OpenQube lo pueden ver [acá](https://sueldos.openqube.io/encuesta-sueldos-2020.01/).

Nuestro objetivo es evaluar modelos de regresión lineal múltiple que buscan explicar el sueldo neto de Data Analysts, Data Scientists y Data Engineers en Argentina.

Es decir, evaluamos los siguientes modelos para el salario neto:

$salarioNeto = \beta_0 +\beta_1X_1+\beta_2X_2+...+\epsilon$

```{r, warning=F, message=F}
library(tidyverse)
library(tidymodels)
```

#### Levantamos Dataset y seleccionamos variables de interés

```{r}
encuesta <- read_csv("../Fuentes/encuesta_RLM_limpia.csv")
df <- encuesta %>%
  select(me_identifico, edad, donde_estas_trabajando, anos_de_experiencia, anos_en_la_empresa_actual, anos_en_el_puesto_actual, gente_a_cargo, trabajo_de, nivel_de_estudios_alcanzado, estado, salario_bruto, salario_neto) 
# agrego columna de nivel educativo alcanzado (agrupa nivel de estudios y estado)
df <- df %>% 
  mutate(nivel_educativo = case_when(nivel_de_estudios_alcanzado %in% c("Posgrado", "Posdoctorado", "Doctorado") ~ "Posgrado", 
                                     TRUE ~ nivel_de_estudios_alcanzado), nivel_edu_alcanzado = paste(nivel_educativo, sep = " ", estado))
df
```
### Partición del dataset en train y test

En este caso para evaluar los modelos vamos a realizar una partición entre dataset de entrenamiento (70%) y testeo (30%) usando la función resample_partition del paquete modelr.

```{r}
# fijamos semilla
set.seed(44)
# Partición Train y Test
train_test <- df %>% 
  modelr::resample_partition(c(train = 0.7, test = 0.3))
# armamos dataframe de testeo y entrenamiento
df_train <- train_test$train %>% as_tibble()
df_test <- train_test$test %>% as_tibble()
# vemos el contenido
df_train %>%
  glimpse() # 170 filas
df_test %>%
  glimpse() # 73 filas
```

Habíamos realizado tres modelos distintos para tratar de explicar el salario neto: 

* Modelo Años de experiencia y Gente a cargo

* Modelo Años de experiencia y Género

* Modelo Años de experiencia y Nivel Educativo Alcanzado

Volvemos a realizar estos modelos utilizando el dataset de entrenamiento:

```{r}
# Modelo Experiencia y Edad
modelo_exp_gc <- lm(salario_neto ~ anos_de_experiencia + gente_a_cargo, data = df_train)
# Modelo Experiencia y Género
modelo_exp_sex <- lm(salario_neto ~ anos_de_experiencia + me_identifico, data = df_train)
# Modelo Experiencia y Nivel Educativo
modelo_exp_edu <- lm(salario_neto ~ anos_de_experiencia + nivel_edu_alcanzado, data = df_train)
```

En el notebook previo sólo habíamos interpretado el valor de los parámetros estimados y su nivel de significación. Ahora buscaremos responder preguntas tales como:

¿Qué proporción de la variabilidad logra explicar el modelo? ¿Cómo decidir que modelo explica mejor el fenómeno?

¿El modelo cumple con los supuestos del modelo lineal?

## Evaluación del Modelo 

Utilizando el paquete broom, vamos a analizar las medidas de resumen del modelo y graficamos coeficientes estimados. 

**Modelo Años de experiencia y Gente a cargo**

```{r}
# medidas de resumen tidy (incluido el intervalo de confianza)
tidy_meg <- tidy(modelo_exp_gc, conf.int = TRUE)
tidy_meg
# Plot de los Coeficientes
ggplot(tidy_meg, aes(estimate, term, xmin = conf.low, xmax = conf.high, height = 0)) +
  geom_point(color = "forestgreen") +
  geom_vline(xintercept = 0, lty = 4, color = "black") +
  geom_errorbarh(color = "forestgreen") +
  theme_bw() +
  labs(y = "Coeficientes β", x = "Estimación")
```
**Modelo Años de experiencia y Género**

```{r}
# medidas de resumen tidy (incluido el intervalo de confianza)
tidy_mes <- tidy(modelo_exp_sex, conf.int = TRUE)
tidy_mes
# Plot de los Coeficientes
ggplot(tidy_mes, aes(estimate, term, xmin = conf.low, xmax = conf.high, height = 0)) +
  geom_point(color = "forestgreen") +
  geom_vline(xintercept = 0, lty = 4, color = "black") +
  geom_errorbarh(color = "forestgreen") +
  theme_bw() +
  labs(y = "Coeficientes β", x = "Estimación")
```
**Modelo Años de experiencia y Nivel Educativo Alcanzado**

```{r}
# medidas de resumen tidy (incluido el intervalo de confianza)
tidy_meed <- tidy(modelo_exp_edu, conf.int = TRUE)
tidy_meed
# Plot de los Coeficientes
ggplot(tidy_meed, aes(estimate, term, xmin = conf.low, xmax = conf.high, height = 0)) +
  geom_point(color = "forestgreen") +
  geom_vline(xintercept = 0, lty = 4, color = "black") +
  geom_errorbarh(color = "forestgreen") +
  theme_bw() +
  labs(y = "Coeficientes β", x = "Estimación")
```

### Coeficientes de determinación R2 ajustado

El R2 permite medir el porcentaje de variabilidad del fenómeno que el modelo logra explicar. Sin importar la relevancia de la variable el R2 aumenta al agregar una variable adicional al modelo, aunque no se incremente la capacidad explicativa. 

Como el R2 no toma en cuenta el número de parámetros en el modelo de regresión, un criterio de decisión mucho más objetivo y automatizable es calcular y comparar modelos por medio del R2 ajustado. 

$$ R^2_{a,p} = 1 − \frac{\frac{SSRes_p}{n − p}}{\frac{SSTotal}{n − 1}} $$
Como SSTotal/n−1 está fijo en un conjunto de datos dado (sólo depende de las
Y observadas), el R2a aumenta si y sólo si el MSResp disminuye.

Veamos qué pasa con los ajustes qué hicimos. 

```{r}
# modelo expriencia y gente a cargo
glance(modelo_exp_gc)
# modelo experiencia y género
glance(modelo_exp_sex)
# modelo experiencia y nivel educativo
glance(modelo_exp_edu)
```

¿Cuál es el modelo que mejor explica la variabildad del conjunto?

Un primer criterio para comparar modelos es mirar el R2 obtenido con cada uno de ellos y elegir aquél con mayor R2 ajustado


```{r}
au_mes <- augment(modelo_exp_sex)
au_mes
```

1) medidas de evaluación  de R cuadrado ajustado
2) medidas de predicción
3) una discusión más general de explicación VS predicción