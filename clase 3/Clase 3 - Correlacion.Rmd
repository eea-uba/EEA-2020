---
title: "Correlación"
author: "Juan Barriola y Sofía Perini"
date: "19 de Septiembre de 2020"
output:
  html_notebook:
    theme: spacelab
    toc: yes
    toc_float: yes
    df_print: paged
---

```{r message=FALSE}
library(tidyverse)
library(openintro)
library(GGally)
library(corrr)
library(knitr)
library(kableExtra)
options(knitr.table.format = "html") 
```

En estas notas de clase veremos el concepto de correlación. Recordemos que la correlación mide el grado de asociación lineal entre dos variables y se calcula con la siguiente fórmula. 

#### Coeficiente de Correlación poblacional: 

$$\rho_{x,y}=\frac{cov(x,y)}{\sigma_x \sigma_y}$$

¿Cómo estimar ese valor poblacional desconocido? Con un estimador muestral. 

Para analizar la correlación, se utilizará el dataset ```mtcars``` que consiste en datos de pruebas en carretera de automóviles extraidos de la revista Motor Trend de EE.UU. de 1974 (*Motor Trend Car Road Tests*), incluidos el consumo de combustible y aspectos del diseño y rendimiento de 32 modelos distintos de autos (modelos 1973–74).

Primero, veamos el contenido del dataset con la función `glimpse()`. 

```{r}
glimpse(mtcars)
```

Se trata de un dataframe de 32 observaciones (modelos de autos) y 11 variables numéricas que los caracterizan. 

También se puede ver el contenido haciendo un `head()` de la tabla. Usando la librería `knitr`, la función `kable()` permite realizar mejores presentaciones de resultados de tablas en HTLM. Con `kable_styling()` se pueden modificar algunas de sus características.

```{r}
mtcars %>% 
  head() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c("striped"))
```

## Graficando la Correlación

#### Librería GGally

Como ya se vio, con `ggpairs()` podemos graficar todas las variables y buscar las correlaciones, agrupando por alguna variable de interés.  

En este caso, vamos a agrupar (colorear) por:

-$am$: Tipo de transmisión: automática (am = 0) o manual (am = 1)

```{r message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
mtcars %>% 
  select(-carb,-vs) %>% # desestimamos algunas variables
  mutate(cyl = factor(cyl), 
         am = factor(am)) %>% 
  ggpairs(., 
        title = "Matriz de correlaciones",
        mapping = aes(colour = am))
```

Los scatterplots permiten ver la forma de la asociación, el sentido y la fuerza. 

#### Librería [corrr](https://github.com/tidymodels/corrr) 

Esta librería pertenece al entorno de _tidymodels_. Devuelve la matriz de correlacion en forma de dataframe (en lugar de matriz) y permite visualizar la información no repetida de la matriz, mostrando las correlaciones sólo debajo de la diagonal principal. 

```{r}
mtcars %>% 
 correlate() %>% # convierte la matriz de corr en dataframe
  shave() %>% # solo muestra información debajo de la diagonal principal
  fashion() # acomoda los datos en forma tidy (por ej. redondeo de decimales)
```

También existen otras formas de visualización de los datos. Con la función `network_plot()` se genera un gráfico de red para los datos de la matriz de correlación en el que las variables que están más correlacionadas aparecen más cercanas y están unidas por caminos más fuertes. Los caminos también están coloreados por su signo (azul para asociación positiva y rojo para negativa).

```{r}
mtcars %>% 
 correlate() %>% 
  network_plot(min_cor = 0.7)
```

Con la función `rplot()` se puede visualizar la matriz de correlación como círculos de colores que representan la intensidad y sentido de la asociación lineal. 

```{r}
mtcars %>% 
 correlate() %>% 
  rplot()
```

## Analizando algunos casos particulares

Veamos la correlación entre las variables:

- $mpg$: Miles/(US)gallon. Eficiencia de combustible (millas por galón)
- $hp$: Gross horsepower. Potencia del motor

Miramos el scatter plot y pareciera haber una relación negativa. 

La mitad superior de la matriz muestra la estimación puntual de la correlación, para todos los datos y considerando cada conjunto por separado. 

Recordemos que la fórmula para calcular ese estimador es:

#### Coeficiente de Correlación de Pearson:

$$
r = \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2} \sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}}
$$

Si quisieramos testear la significatividad de este estimador. Es decir, si existe asociación lineal en el parámetro poblacional:

$H_0$ : ρ = 0        
$H_1$ : ρ $\neq$ 0      

* Supuestos: las observaciones deben ser i.i.d. y la distribución conjunta debe ser normal bivariada. 

```{r}
cor.test(mtcars$mpg, mtcars$hp, method = "pearson")
```

```{r}
cor.test(mtcars$mpg, mtcars$hp, method = "spearman")
```

Con estos p-valor, se rechazaría la $H_0$ (no existe asociación lineal entre las variables), es decir, existe evidencia estadísticamente significativa a favor de la asociación lineal entre las variables mpg y hp. 

Testeando normalidad multivariada:

```{r}
mvnormtest::mshapiro.test(t(mtcars[,c("mpg", "hp")])) # chequeo normalidad bivariada
```

No se cumple normalidad bivariada. Entonces, el test para la correlación de pearson no sería válido ya que no se cumple el supuesto de normalidad multivariada. En cambio, el de spearman no requiere dicho supuesto y sus conclusiones sí serían válidas.  

¿Y si queremos comparar la relación entre $drat$ y $gear$?

- $drat$: la relación de engranaje del eje trasero. En los vehículos con tracción trasera, la relación de eje trasero es una parte importante de una ecuación de remolque exitosa. Se expresa como la relación entre las revoluciones por minuto del eje de transmisión y las revoluciones por minuto del eje trasero. Una relación "alta", con un número alto de rotaciones del eje de transmisión, es mejor para una aceleración rápida, los grados de ascenso, el transporte de cargas o el remolque. Sin embargo, ofrece menos ahorro de combustible y se produce más ruido cuando el vehículo circula a alta velocidad.
- $gear$: Número de velocidades hacia adelante.

Con `ggpairs()` ya habíamos visto que la relación era diferente entre los automáticos y con transmisión manual. Sabiendo esto, volvamos a calcular los estimadores puntuales de cada grupo. 

```{r}
mtcars %>% 
  group_by(am) %>% 
  summarise(cor = cor(drat, gear))
```

Los autos atomáticos parecen tener correlación positiva y alta, mientras los manuales negativa y baja. 

Tomando el primer grupo, graficamos boxplot paralelos de la variable gear para ver cómo se distribuye drat:

```{r}
mtcars2 <- mtcars %>% filter(am == 0)
ggplot(mtcars2, aes(gear, drat, group = gear, fill = factor(gear)))+
  geom_boxplot(alpha = 0.75)
```

No parece muy correcto hacer un test de correlación de pearson, es decir buscar una relación lineal, con una variable que sólo toma dos valores (3 y 4).

Usemos el test de correlación de Spearman, que no necesita cumplir supuesto de normalidad para testearse. 

```{r}
cor.test(mtcars2$gear, mtcars2$drat, method = "pearson")
cor.test(mtcars2$gear, mtcars2$drat, method = "spearman")
```

Se puede notar que el test de Spearman ya no da tan significativo como el de Pearson.

* Testeando normalidad multivariada 

```{r}
mvnormtest::mshapiro.test(t(mtcars2[,c("gear", "drat")])) # chequeo normalidad bivariada
```