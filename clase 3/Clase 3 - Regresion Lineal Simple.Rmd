---
title: "Regresión Lineal Simple"
author: "Juan Barriola y Sofía Perini"
date: "19 de Septiembre de 2020"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

# Encuesta de Sueldos en el sector IT

Vamos a trabajar con un dataset de la encuesta de sueldos en el sector de tecnología en Argenina realizada por SysArmy. El informe, realizado por OpenQube lo pueden ver (acá)[https://sueldos.openqube.io/encuesta-sueldos-2020.01/]

Nuestro objetivo es crear un modelo para explicar el sueldo neto de Data Analysts, Data Scientists y Data Engineers en Argentina


```{r}
# Carga de librerías
library(tidyverse)
library(corrr)
library(knitr)
library(kableExtra)
library(GGally)
```


## Preparación de Datos

Comenzamos leyendo los datos y viendo su estructura

```{r, message=FALSE}
encuesta <- read_csv("../Fuentes/encuesta_sueldos_sysarmy_1s2020.csv")
encuesta %>%
  glimpse()
```

Existen 5.982 respuestas de 53 preguntas distintas. Nos vamos a quedar con las respuestas de las personas que trabajan como Data Analysts, Data Scientists y Data Engineers.

```{r}
# Filtro de los perfiles de interes
encuesta_ds = encuesta %>%
                filter(trabajo_de %in% c("Data Scientist / Data Engineer", "BI Analyst / Data Analyst"))

# Función para describir las dimensiones
dim_desc(encuesta_ds)
```

Existen 321 respuestas que cumplen con este criterio

## Análisis exploratorio I

Realicemos algunos análisis exploratorios para conocer mejor el dataset.

### Valores únicos y faltantes

Una de las primeras características para revisar en un dataset es la cantidad de valores únicos y porcentaje de valores faltantes que tiene cada variable.

```{r}
tabla_exploratorios =  encuesta_ds %>%
                                      gather(., 
                                            key = "variables", 
                                            value = "valores") %>% # agrupamos por las variables del set
                                      group_by(variables) %>% 
                                      summarise(valores_unicos = n_distinct(valores),
                                      porcentaje_faltantes = sum(is.na(valores))/nrow(encuesta_ds)*100) %>% 
                                      arrange(desc(porcentaje_faltantes), valores_unicos) # ordenamos por porcentaje de faltantes y valores unicos
tabla_exploratorios
```

Vemos que varias variables presentan un alto porcentaje de faltantes. Podemos observar aquellas variables que tienen faltantes en un gráfico. 

```{r}
tabla_exploratorios %>% filter(porcentaje_faltantes>0) %>% 
ggplot(., aes(x=reorder(variables, -porcentaje_faltantes), y=porcentaje_faltantes, fill=porcentaje_faltantes)) +
  geom_bar(stat = "identity") +
  scale_fill_gradient(high = "firebrick", low = "orange") +
  scale_x_discrete(label = function(x) stringr::str_trunc(x, 18)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=80, vjust=0.5), legend.position = "none") +
  labs(title='Porcentaje de valores faltantes', y='Porcentaje de faltantes', x='') 
```

La variable a predecir,**salario neto** presenta 10 valores faltantes.

### Selección de variables 

Seleccionamos las variables que nos interesan. Es la variable a predecir: **salario neto** y 7 variables más.

```{r}
encuesta_ds_relevantes = encuesta_ds %>%
                              # Seleccionamos las variables de interés
                              select(tengo, anos_de_experiencia, anos_en_la_empresa_actual, anos_en_el_puesto_actual,
                                     trabajo_de, salario_mensual_bruto_en_tu_moneda_local,
                                     salario_mensual_neto_en_tu_moneda_local, sueldo_dolarizado) %>% 
                              #Renombramos algunas variables
                              rename(edad = tengo,
                                     perfil = trabajo_de,
                                     salario_bruto = salario_mensual_bruto_en_tu_moneda_local,
                                     salario_neto = salario_mensual_neto_en_tu_moneda_local)
```

### Analisis exploratorios I

Realizamos un primer análisis descriptivo de nuestro dataset de columnas relevantes. Para ello utilizamos la función `ggpairs` sobre las variables numéricas con una apertura por la variable de perfil.

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=6}
encuesta_ds_relevantes %>% select(-sueldo_dolarizado) %>%
  ggpairs(aes(color=perfil), legend = 25) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, vjust=0.5), legend.position = "bottom")
```

Respecto de nuestra variable a predecir, el **salario neto**, observamos:
  * Todas las variables (excepto el salario bruto) presentan una correlación muy baja con esta variable
  * En los gráficos de dispersión con las variables de edad, salario bruto, años de experiencia y años en el puesto se observan varios puntos que parecen ser outliers 

Existen más respuestas de *BI Analyst/Data Analyst* que de *Data Scientist/Data Engineer* aunque no es una gran diferencia.
  
Parece existir:
  * un outlier severo en la variable **años en la empresa**
  * algunas observaciones con una relación "extraña" entre la edad y los años de experiencia

## Limpieza de datos

En base a nuestro análisis de valores faltantes y exploratorios procedemos a realizar la limpieza de nuestro dataset

### Delimitar el modelo: Sueldo dolarizado

Eliminamos aquellas observaciones con el sueldo dolarizado para no incluir variaciones vinculadas al tipo de cambio en nuestro set de datos

```{r}
encuesta_ds_relevantes %>% 
  filter(sueldo_dolarizado==1) %>% # Observaciones con el sueldo dolarizado
  nrow()
```

Este filtro elimina 20 observaciones

### Datos faltantes

En el apartado anterior observamos que, de las variables relevantes, sólo nuestra variable a predecir **salario_neto** presentaba 10 valores faltantes. Frente a esta situación podríamos elegir una estrategia para imputar valores faltantes o eliminarlos. Como no se tratan de muchos registros vamos a eliminarlos con la función `drop_na`

```{r}
encuesta_ds_relevantes = encuesta_ds_relevantes %>% 
  drop_na(salario_neto)
```

### Datos inconsistentes

Comencemos analizando aquellos registros que presentan datos que no son consistentes. 

#### Edad vs años de experiencia

Como ya mencionamos, parecen existir algunos registros con una relación "extraña" entre la edad y los años de experiencia. Realizamos el gráfico de dispersión entre estas dos variables para analizar mejor su relación 

```{r}
ggplot(encuesta_ds_relevantes, aes(x=edad, y=anos_de_experiencia)) +
        geom_point() +
        theme_bw() +
        labs(x="Edad", y="Años de experiencia", title = "Edad vs Años de experiencia")
```

Existen dos situaciones problemáticas:

* los años de experiencia superan a la edad
* sabiendo que la edad mínima para trabajar en Argentina es 14 años, podemos revisar en que registros la diferencia entre la edad y los años de experiencia es menor a dicho umbral

Veamos cuantos registros eliminamos con estos filtros 
```{r}
edad_laboral_minima = 14
encuesta_ds_relevantes %>% 
  filter(edad-anos_de_experiencia<=edad_laboral_minima) %>% # filtro de los problemas con la edad
  select(edad, anos_de_experiencia)
```

Son 9 registros en los cuales hay casos de ambas problemáticas

**Caso particular: Años de experiencia en la empresa actual**

Habíamos observado que existe un outlier severo en la variable de años de experiencia en la empresa actual. Grafiquemos dicha variable en un boxplot:

```{r}
ggplot(encuesta_ds_relevantes, aes(y=anos_en_la_empresa_actual)) + geom_boxplot() + theme_bw()
```

```{r}
encuesta_ds_relevantes %>% filter(anos_en_la_empresa_actual>70)
```

En este caso la persona parece haber contestado con el año en el cual ingreso a la empresa. Podríamos reconstruir el dato o eliminarlo, por simplicidad vamos a elegir la segunda opción.

#### Salario neto superior al bruto

Pueden existir registros en los cuales el salario neto supere al bruto, lo cual es una inconsistencia en los datos.

```{r}
ggplot(encuesta_ds_relevantes, aes(x=salario_bruto, y=salario_neto, color = salario_neto<salario_bruto)) +
        geom_point() +
        theme_bw() +
        labs(title = "Inconsistencias en el salario", x="Salario Bruto", y="Salario Neto", color="¿Registro consistente?")
```

En el gráfico observamos que existen algunos registros con datos inconsistentes

```{r}
encuesta_ds_relevantes %>%
  filter(salario_bruto<salario_neto) %>% 
  select(salario_bruto, salario_neto)
```

Al igual que antes podríamos tratar de imputar un valor para nuestra variable a predecir o eliminarlos. Al tratarse de 6 registros los vamos a eliminar.

#### Conjunto de filtros

Realizamos todos los filtros que fuimos describiendo en las subsecciones pasadas para quedarnos con un conjunto de datos consistentes según los criterios que definimos previamente.

```{r}
# Conjunto de filtros
encuesta_ds_filtrada = encuesta_ds_relevantes %>%
                          filter(sueldo_dolarizado==0, #Eliminamos los sueldos dolarizados
                                 edad-anos_de_experiencia>=edad_laboral_minima, # Eliminamos registros inconsistentes con la edad laboral
                                 salario_bruto>salario_neto, # Inconsistencia en los sueldos
                                 anos_en_la_empresa_actual<70) %>%  # Error de carga
                          select(-sueldo_dolarizado) # Eliminamos la columna de sueldo dolarizado
```

### Análisis exploratorio II

Habiendo aplicado los filtros volvemos a realizar el análisis exploratorio con ggpairs 

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=6}
encuesta_ds_filtrada %>%
  ggpairs(aes(color=perfil), legend = 25) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, vjust=0.5), legend.position = "bottom")
```

Respecto de nuestra variable a predecir, el **salario neto**, observamos:
  * Todas las variables (excepto el salario bruto) siguen presentando una correlación general muy baja con esta variable
  * Sin embargo, la edad y años de experiencia presentan un correlación positiva moderada para el grupo de *Data Scientist/Data Engineer*
  * Siguen existiendo outliers

### Outliers Univariados

Analicemos la existencia de outliers del salario neto mensual

#### Boxplot

Comenzamos graficando el boxplot de la variable.

```{r}
ggplot(encuesta_ds_filtrada, aes(y=salario_neto)) +
  geom_boxplot() +
  theme_bw() +
  labs(title="Distribución salario neto", y="Salario Neto")

```

El gráfico nos indica que existen outliers "superiores" de acuerdo al criterio del boxplot. 

Recordemos que con el criterio del rango intercuartil (boxplot):

Un outlier "superior" se define como aquel valor *q* el cual cumple:

$q> Q_3 + 1.5 \cdot IQR$

UN outlier "inferior" se define como aquel valor *q* el cual cumple:

$q< Q_1 - 1.5 \cdot IQR$

Siendo $Q_1$: primer cuartil, $Q_3$: tercer cuartil e $IQR=Q_3 - Q_1$: rango intercuartil

Construimos el límite superior e inferior para identificar y filtrar outliers

```{r}
limite_superior_outliers = IQR(encuesta_ds_filtrada$salario_neto) * 1.5 + quantile(encuesta_ds_filtrada$salario_neto, 0.75)[[1]]
limite_superior_outliers
```

Veamos cuántos registros superan dicho límite

```{r}
encuesta_ds_filtrada %>% filter(salario_neto>limite_superior_outliers)
```

Son 10 registros en total. Existen 2 registros (filas 3 y 10) que parecen ser errores de carga, los registros restantes parecen ser outliers "genuinos".

Construimos el limite inferior

```{r}
limite_inferior_outliers =quantile(encuesta_ds_filtrada$salario_neto, 0.25)[[1]] - IQR(encuesta_ds_filtrada$salario_neto) * 1.5
limite_inferior_outliers 
```

El límite inferior es negativo, por lo tanto no tiene sentido filtrar por dicho valor.
Eliminamos los outliers superiores según este criterio

```{r}
encuesta_ds_sin_outliers = encuesta_ds_filtrada %>% filter(salario_neto<=limite_superior_outliers)
```

#### Percentiles

Dada la distribución de los datos deberíamos estudiar que sucede en la cola izquierda de la distribución.
Creamos una función que nos permita observar los percentiles de una variable en una tabla.

```{r}
# Funcion para crear una tabla con los percentiles deseados de la variable
crear_tabla_percentiles <- function(vector, q = c(0.25, 0.5, 0.75)) {
  tibble("{{ vector }}" := quantile(vector, q), "{{ vector }}_q" := q)
}

# Creamos el vector del salario
salario_neto_vec = encuesta_ds_sin_outliers$salario_neto

# Creamos la tabla de percentiles en intervalos de a 5%
percentiles_salario_neto = crear_tabla_percentiles(salario_neto_vec, c(seq(0,.1,0.01)))
percentiles_salario_neto
```

Vemos que hasta el percentil 3 los valores son anormalmente bajos pero no podían ser filtrados por el criterio anterior. Un valor apropiado para filtrar valores bajos es el del percentil 5

```{r}
# Seleccionamos el valor del salario neto del percentil 5
limite_inferior_percentil = percentiles_salario_neto %>% 
                                filter(salario_neto_vec_q==0.05) %>%
                                select(salario_neto_vec) %>%
                                as.numeric()
```

Eliminamos los outliers superiores según este criterio. Al tratarse del percentil 5, sabemos que estamos perdiendo 5% de los datos

```{r}
encuesta_ds_final = encuesta_ds_sin_outliers %>%
  filter(salario_neto >= limite_inferior_percentil)
```

### Análisis exploratorio III

Habiendo eliminado los outliers univariados de la variable respuesta realizamos un último análisis exploratorio con ggpairs 

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=6}
encuesta_ds_final %>%
  ggpairs(aes(color=perfil), legend = 25) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, vjust=0.5), legend.position = "bottom")
```

Ahora, respecto de nuestra variable a predecir, el **salario neto**, observamos:
  * Existe una correlación positiva moderada con la edad y los años de experiencia
  * Existe una correlación positiva baja con los años en la empresa y los años en el puesto. Respecto a esta última variable existe una gran diferencia en la correlación entre los dos perfiles 
  * Ya no existen outliers

### Chequeo correlación

```{r}

# calculo matriz de correlacion para los registros completos (omitiendo faltantes) para variables numéricas con ambos métodos 

# pearson
matriz.correl.pe <- encuesta_ds_final %>%
  select_if(is.numeric) %>% 
 correlate(use = "complete.obs", method = "pearson") %>% 
  shave() %>% 
  fashion()
matriz.correl.pe

# spearman
matriz.correl.sp <- encuesta_ds_final %>%
  select_if(is.numeric) %>% 
 correlate(use = "complete.obs", method = "spearman") 
matriz.correl.sp
```

## Modelos

$salarioNeto = \beta_0 +\beta_1x+\epsilon$

### Modelo edad

```{r}
modelo_edad = lm(salario_neto ~ anos_de_experiencia, encuesta_ds_final)
modelo_edad %>% summary()
```

```{r}
encuesta_ds_final %>% ggplot(., aes(x = edad, y = salario_neto)) + 
  geom_point() +
  geom_abline(method = "lm", col = "red") + 
  theme_bw()
```

### Modelo años de experiencia

```{r}
lm(salario_neto ~ anos_de_experiencia, encuesta_ds_final) %>%
  summary()
```

```{r}
encuesta_ds_final %>% ggplot(., aes(x = anos_de_experiencia, y = salario_neto)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red") + 
  theme_bw()
```


## Modelo Lineal Simple^[Fuente: Apunte de Regresión Lineal - María Eugenia Szretter Noste] 

El modelo lineal (simple pues sólo vincula una variable predictora con Y) propone que:

$$
Y = \beta_0 + \beta_1X + \epsilon
$$
donde $\epsilon$ es el término del error, $\beta_0$ y $\beta_1$ son constantes desconocidas que se denominan parámetros del modelo, o coeficientes de la ecuación. El modelo se denomina lineal pues propone que la Y depende linealmente de X. 

El modelo en términos de las observaciones (Xi; Yi):

$$
Y_i = \beta_0 + \beta_1X_i + \epsilon_i
$$
donde $\epsilon_i$ es el término del error para el individuo i-ésimo, que no es observable.

### Supuestos del modelo lineal

Se pueden resumir como $\epsilon_i$ ~ $N(0,\sigma^2)$ 1<i<n, independientes entre sí.

El modelo en términos de la esperanza de Y condicional a las X's que notaremos
E(Y|X):

$$
E(Y|X) = \beta_0 + \beta_1X
$$

Se la suele llamar función de respuesta, es una recta.

### Ajuste del Modelo

Se quiere ajustar un modelo para el salario bruto en función de los años de experiencia. 

$$ \hat{Y} = \hat{\beta_0} + \hat{\beta_1}X $$
```{r, warning=F}
# ajustamos modelo lineal simple
lm1 <- lm(salario_bruto ~ `Años de experiencia`, df2) 
lm1 %>%
  summary()
# graficamos la recta ajustada
ggplot(df2, aes(x = `Años de experiencia`, y = salario_bruto)) + 
  geom_point() +
  geom_smooth(method = "lm", se = T, col = "dodgerblue") + 
  theme_minimal() 
```

La recta ajustada a esos datos es:

$$ \hat{Y} =  61.270,2 + 3.143,9X $$
Es decir, la ordenada al origen estimada resulta ser 61.270,2 y la pendiente de la recta estimada es 3.143,9. 

### Significado de los coeficientes estimados 

El valor de la ordenada al origen es el valor de salario bruto esperado para alguien sin experiencia laboral (0 años de experiencia). La pendiente de la recta es 3.143,9, lo que implica que por cada año adicional de experiencia, el sueldo bruto aumenta $3.143,9 en promedio. 

### Intervalos de Confianza y de Predicción

Calculemos los intervalos de confianza de nivel 0,95 para $E(Y_h/X = x_h)$ y de predicción para una nueva observación $Y_h$ realizada cuando $X = x_h$.

¿Cuál es mayor? ¿Por qué?

```{r}
# armamos un data frame con nuevos datos de ejemplo
nuevos_datos <- c(5,17,23) # anos de experiencia
nuevos_datos <- data.frame(nuevos_datos) %>%
  rename("Años de experiencia" = nuevos_datos)
# calculamos intervalos de confianza y predicción
IC <- predict(lm1, newdata = nuevos_datos, interval = "confidence", level = 0.95)
IP <- predict(lm1, newdata = nuevos_datos, interval = "prediction", level = 0.95)
IC
IP
```

* **Estimación** (es decir, el cálculo del intervalo de confianza para la esperanza de Y condicional al valor de X $E(Y_h/X = x_h)$): Es una regla para calcular a partir de los datos un valor que nos permita "adivinar" el valor que puede tomar un parámetro poblacional, en este caso, la esperanza de Y cuando la variable X toma el valor $x_h$. En el ejemplo, el parámetro es el sueldo bruto medio de todos los empleados con $x_h$ (por ejemplo, 5) anos de experiencia.
* **Predicción** (es decir, el cálculo del intervalo de predicción de una nueva observación $Y_h$(nueva) medida cuando $X = x_h$): Es una regla para calcular a partir de los datos un valor que nos permita "adivinar" el valor que puede tomar una variable aleatoria.

```{r}
# armamos data frame con datos de intervalo de predicción
new_df <- cbind(df2[,c("salario_bruto", "Años de experiencia")], predict(lm1, interval = "prediction"))
# graficamos la recta ajustada con los IP e IC. 
ggplot(new_df, aes(x = `Años de experiencia`, y = salario_bruto)) + 
  geom_point() +
  # agregamos rectas de intervalo de predicción 0.95
  geom_line(aes(y=lwr), color = "red", linetype = "dashed")+
  geom_line(aes(y=upr), color = "red", linetype = "dashed")+
  # recta ajustada con intervalo de confianza de 0.95
  geom_smooth(method = "lm", se = T, col = "dodgerblue") + 
    theme_minimal()
```

Verificamos el valor de los intervalos con el ejemplo anterior. ¿Coinciden? Si. 

```{r, warning=F}
ggplot(df2, aes(y = salario_bruto, x = `Años de experiencia`, colour = `Me identifico`, shape =  `Me identifico`)) +
  geom_smooth(method = "lm") + 
  labs(x = 'Años de experiencia',
    y = "Salario Bruto", 
    title = 'Salario bruto según años de experiencia',
    subtitle = 'Según años, sexo y nivel educativo') +
  theme_minimal()+
  scale_alpha(guide = FALSE)+
  facet_grid(. ~ nivel_educativo)
```

```{r}


```

