---
title: "Regresión Lineal Simple"
author: "Juan Barriola y Sofía Perini"
date: "19 de Septiembre de 2020"
output:
  html_notebook:
    theme: spacelab
    toc: yes
    toc_float: yes
    df_print: paged
---

# Encuesta de Sueldos en el sector IT

Vamos a trabajar con un dataset de la encuesta de sueldos en el sector de tecnología en Argenina realizada por SysArmy. El informe, realizado por OpenQube lo pueden ver (acá)[https://sueldos.openqube.io/encuesta-sueldos-2020.01/]

Nuestro objetivo es crear un modelo para explicar el sueldo neto de Data Analysts, Data Scientists y Data Engineers en Argentina


```{r}
# Carga de librerías
library(tidyverse)
library(corrr)
library(knitr)
library(kableExtra)
library(GGally)
```


## Preparación de Datos

Comenzamos leyendo los datos y viendo su estructura

```{r}
encuesta <- read_csv("../Fuentes/encuesta_sueldos_sysarmy_1s2020.csv")
encuesta %>%
  glimpse()
```

Existen 5.982 respuestas de 53 preguntas distintas. Nos vamos a quedar con las respuestas de las personas que trabajan como Data Analysts, Data Scientists y Data Engineers.

```{r}
# Filtro de los perfiles de interes
encuesta_ds = encuesta %>%
                filter(trabajo_de %in% c("Data Scientist / Data Engineer", "BI Analyst / Data Analyst"))

# Función para describir las dimensiones
dim_desc(encuesta_ds)
```

Existen 321 respuestas que cumplen con este criterio

## Análisis exploratorio

Realicemos algunos análisis exploratorios para conocer mejor el dataset.

### Valores únicos y faltantes

Una de las primeras características para revisar en un dataset es la cantidad de valores únicos y porcentaje de valores faltantes que tiene cada variable.

```{r}
tabla_exploratorios =  encuesta_ds %>%
                                      gather(., 
                                            key = "variables", 
                                            value = "valores") %>% # agrupamos por las variables del set
                                      group_by(variables) %>% 
                                      summarise(valores_unicos = n_distinct(valores),
                                      porcentaje_faltantes = sum(is.na(valores))/nrow(encuesta_ds)*100) %>% 
                                      arrange(desc(porcentaje_faltantes), valores_unicos) # ordenamos por porcentaje de faltantes y valores unicos
tabla_exploratorios
```

Vemos que varias variables presentan un alto porcentaje de faltantes



```{r}
tabla_exploratorios %>% filter(porcentaje_faltantes>0) %>% 
ggplot(., aes(x=reorder(variables, -porcentaje_faltantes), y=porcentaje_faltantes, fill=porcentaje_faltantes)) +
  geom_bar(stat = "identity") +
  scale_fill_continuous("reds") +
  scale_x_discrete(label = function(x) stringr::str_trunc(x, 18)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=80, vjust=0.5)) +
  labs(title='Porcentaje de valores faltantes', y='Porcentaje de faltantes', x='') 
```


### Filtros 

Se seleccionan las variables de interes.

```{r}
encuesta_ds_relevantes = encuesta_ds %>%
                              select(tengo, anos_de_experiencia, anos_en_la_empresa_actual, anos_en_el_puesto_actual,
                                     trabajo_de, salario_mensual_bruto_en_tu_moneda_local,
                                     salario_mensual_neto_en_tu_moneda_local, sueldo_dolarizado) %>% 
                              rename(edad = tengo,
                                     salario_bruto = salario_mensual_bruto_en_tu_moneda_local,
                                     salario_neto = salario_mensual_neto_en_tu_moneda_local)
```


Descripcion

```{r, message=FALSE, warning=FALSE}
encuesta_ds_relevantes %>% select(-sueldo_dolarizado) %>% ggpairs(aes(color=trabajo_de)) + 
  theme_bw()
```

## Limpieza de datos

### Limites del estudio

#### Sueldo dolarizado

Eliminar aquellas observaciones con el sueldo dolarizado para no incluir variaciones vinculadas al tipo de cambio en nuestro set de datos

```{r}
encuesta_ds_relevantes %>% filter(sueldo_dolarizado==1)
```


### Datos inconsistentes

Comencemos analizando aquellos registros que presentan datos que no son consistentes. 

#### Edad vs años de experiencia

Parecen existir algunos registros en los cuales la experiencia laboral supera la edad. 

```{r}
ggplot(encuesta_ds_relevantes, aes(x=edad, y=anos_de_experiencia, color=edad-anos_de_experiencia)) +
        geom_point() +
        theme_bw()
```

Sabiendo que la edad mínima para trabajar en Argentina es 14 años, podemos revisar en que registros la diferencia entre la edad y los años de experiencia es menor a dicho umbral.

```{r}
edad_laboral_minima = 14
encuesta_ds_relevantes %>% filter(edad-anos_de_experiencia<edad_laboral_minima)
```

**Caso particular: Años de experiencia en la empresa actual**

Hay un caso particular en el cual una persona contestó que lleva 2016 años en la empresa actual

```{r}
encuesta_ds_relevantes %>% filter(anos_en_la_empresa_actual>70)
```


### Salario neto superior al bruto

```{r}
ggplot(encuesta_ds_relevantes, aes(x=salario_mensual_bruto_en_tu_moneda_local, y=salario_mensual_neto_en_tu_moneda_local)) +
         geom_point() + theme_bw()
```


```{r}
encuesta_ds_relevantes %>% mutate(dif=(salario_mensual_bruto_en_tu_moneda_local-salario_mensual_neto_en_tu_moneda_local)/salario_mensual_bruto_en_tu_moneda_local) %>% arrange(desc(dif))
```


```{r}
encuesta_ds_relevantes %>% filter(salario_bruto<salario_neto)
```


```{r}
encuesta_ds_filtrada = encuesta_ds_relevantes %>%
                          filter(sueldo_dolarizado==0, #Eliminamos los sueldos dolarizados
                                 edad-anos_de_experiencia>edad_laboral_minima, # Eliminamos registros inconsistentes con la edad laboral
                                 salario_bruto>salario_neto, # Inconsistencia en los sueldos
                                 anos_en_la_empresa_actual<70) # Error de carga
```

```{r, message=FALSE, warning=FALSE}
encuesta_ds_filtrada %>% select(-sueldo_dolarizado) %>% ggpairs(aes(color=trabajo_de)) + 
  theme_bw()
```

### Chequeo Outliers Univariados

Chequeamos outliers del salario neto por mes.

Boxplot

```{r}
ggplot(encuesta_ds_filtrada, aes(y=salario_neto)) + geom_boxplot() + theme_bw()
```

```{r}
tabla_cuantiles <- function(x, q = c(0.25, 0.5, 0.75)) {
  tibble("{{ x }}" := quantile(x, q), "{{ x }}_q" := q)
}

vector_salario_neto = encuesta_ds_filtrada$salario_neto

tabla_cuantiles(vector_salario_neto, c(seq(0,1,0.05)))
```

```{r}
IQR(encuesta_ds_filtrada$salario_neto) * 1.5 + quantile(encuesta_ds_filtrada$salario_neto, 0.75)
```


```{r}
quantile(encuesta_ds_filtrada$salario_neto, 0.25) - IQR(encuesta_ds_filtrada$salario_neto) * 1.5  
```


```{r}
ggplot(encuesta_ds_filtrada, aes(x=trabajo_de, y=salario_neto, fill=trabajo_de)) + geom_boxplot() + theme_bw()
```


```{r}
encuesta_ds_final = encuesta_ds_filtrada %>% filter(between(salario_neto, 21350.00, 137000))
```

```{r}
ggplot(encuesta_ds_final, aes(x=trabajo_de, y=salario_neto, fill=trabajo_de)) + geom_boxplot() + theme_bw()
```

```{r, message=FALSE, warning=FALSE}
encuesta_ds_final %>% select(-sueldo_dolarizado) %>% ggpairs(aes(color=trabajo_de)) + 
  theme_bw()
```

### Chequeo correlación

```{r}

# calculo matriz de correlacion para los registros completos (omitiendo faltantes) para variables numéricas con ambos métodos 

# pearson
matriz.correl.pe <- encuesta_ds_final %>%
  select_if(is.numeric) %>% 
 correlate(use = "complete.obs", method = "pearson") %>% 
  shave() %>% 
  fashion()
matriz.correl.pe

# spearman
matriz.correl.sp <- encuesta_ds_final %>%
  select_if(is.numeric) %>% 
 correlate(use = "complete.obs", method = "spearman") 
matriz.correl.sp
```

## Modelos

$salarioNeto = \beta_0 +\beta_1x+\epsilon$

### Modelo edad

```{r}
lm(salario_neto ~ anos_de_experiencia, encuesta_ds_final) %>%
  summary()
```

```{r}
encuesta_ds_final %>% ggplot(., aes(x = edad, y = salario_neto)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red") + 
  theme_bw()
```

### Modelo años de experiencia

```{r}
lm(salario_neto ~ anos_de_experiencia + trabajo_de, encuesta_ds_final) %>%
  summary()
```

```{r}
encuesta_ds_final %>% ggplot(., aes(x = anos_de_experiencia, y = salario_neto)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red") + 
  theme_bw()
```

```{r}
encuesta_ds_final %>% filter(trabajo_de =="Data Scientist / Data Engineer") %>% ggplot(., aes(x = anos_de_experiencia, y = salario_neto)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red") + 
  theme_bw()
```

```{r}
encuesta_ds_final %>% filter(trabajo_de =="BI Analyst / Data Analyst") %>% ggplot(., aes(x = anos_de_experiencia, y = salario_neto)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red") + 
  theme_bw()
```


## Modelo Lineal Simple^[Fuente: Apunte de Regresión Lineal - María Eugenia Szretter Noste] 

El modelo lineal (simple pues sólo vincula una variable predictora con Y) propone que:

$$
Y = \beta_0 + \beta_1X + \epsilon
$$
donde $\epsilon$ es el término del error, $\beta_0$ y $\beta_1$ son constantes desconocidas que se denominan parámetros del modelo, o coeficientes de la ecuación. El modelo se denomina lineal pues propone que la Y depende linealmente de X. 

El modelo en términos de las observaciones (Xi; Yi):

$$
Y_i = \beta_0 + \beta_1X_i + \epsilon_i
$$
donde $\epsilon_i$ es el término del error para el individuo i-ésimo, que no es observable.

### Supuestos del modelo lineal

Se pueden resumir como $\epsilon_i$ ~ $N(0,\sigma^2)$ 1<i<n, independientes entre sí.

El modelo en términos de la esperanza de Y condicional a las X's que notaremos
E(Y|X):

$$
E(Y|X) = \beta_0 + \beta_1X
$$

Se la suele llamar función de respuesta, es una recta.

### Ajuste del Modelo

Se quiere ajustar un modelo para el salario bruto en función de los años de experiencia. 

$$ \hat{Y} = \hat{\beta_0} + \hat{\beta_1}X $$
```{r, warning=F}
# ajustamos modelo lineal simple
lm1 <- lm(salario_bruto ~ `Años de experiencia`, df2) 
lm1 %>%
  summary()
# graficamos la recta ajustada
ggplot(df2, aes(x = `Años de experiencia`, y = salario_bruto)) + 
  geom_point() +
  geom_smooth(method = "lm", se = T, col = "dodgerblue") + 
  theme_minimal() 
```

La recta ajustada a esos datos es:

$$ \hat{Y} =  61.270,2 + 3.143,9X $$
Es decir, la ordenada al origen estimada resulta ser 61.270,2 y la pendiente de la recta estimada es 3.143,9. 

### Significado de los coeficientes estimados 

El valor de la ordenada al origen es el valor de salario bruto esperado para alguien sin experiencia laboral (0 años de experiencia). La pendiente de la recta es 3.143,9, lo que implica que por cada año adicional de experiencia, el sueldo bruto aumenta $3.143,9 en promedio. 

### Intervalos de Confianza y de Predicción

Calculemos los intervalos de confianza de nivel 0,95 para $E(Y_h/X = x_h)$ y de predicción para una nueva observación $Y_h$ realizada cuando $X = x_h$.

¿Cuál es mayor? ¿Por qué?

```{r}
# armamos un data frame con nuevos datos de ejemplo
nuevos_datos <- c(5,17,23) # anos de experiencia
nuevos_datos <- data.frame(nuevos_datos) %>%
  rename("Años de experiencia" = nuevos_datos)
# calculamos intervalos de confianza y predicción
IC <- predict(lm1, newdata = nuevos_datos, interval = "confidence", level = 0.95)
IP <- predict(lm1, newdata = nuevos_datos, interval = "prediction", level = 0.95)
IC
IP
```

* **Estimación** (es decir, el cálculo del intervalo de confianza para la esperanza de Y condicional al valor de X $E(Y_h/X = x_h)$): Es una regla para calcular a partir de los datos un valor que nos permita "adivinar" el valor que puede tomar un parámetro poblacional, en este caso, la esperanza de Y cuando la variable X toma el valor $x_h$. En el ejemplo, el parámetro es el sueldo bruto medio de todos los empleados con $x_h$ (por ejemplo, 5) anos de experiencia.
* **Predicción** (es decir, el cálculo del intervalo de predicción de una nueva observación $Y_h$(nueva) medida cuando $X = x_h$): Es una regla para calcular a partir de los datos un valor que nos permita "adivinar" el valor que puede tomar una variable aleatoria.

```{r}
# armamos data frame con datos de intervalo de predicción
new_df <- cbind(df2[,c("salario_bruto", "Años de experiencia")], predict(lm1, interval = "prediction"))
# graficamos la recta ajustada con los IP e IC. 
ggplot(new_df, aes(x = `Años de experiencia`, y = salario_bruto)) + 
  geom_point() +
  # agregamos rectas de intervalo de predicción 0.95
  geom_line(aes(y=lwr), color = "red", linetype = "dashed")+
  geom_line(aes(y=upr), color = "red", linetype = "dashed")+
  # recta ajustada con intervalo de confianza de 0.95
  geom_smooth(method = "lm", se = T, col = "dodgerblue") + 
    theme_minimal()
```

Verificamos el valor de los intervalos con el ejemplo anterior. ¿Coinciden? Si. 

```{r, warning=F}
ggplot(df2, aes(y = salario_bruto, x = `Años de experiencia`, colour = `Me identifico`, shape =  `Me identifico`)) +
  geom_smooth(method = "lm") + 
  labs(x = 'Años de experiencia',
    y = "Salario Bruto", 
    title = 'Salario bruto según años de experiencia',
    subtitle = 'Según años, sexo y nivel educativo') +
  theme_minimal()+
  scale_alpha(guide = FALSE)+
  facet_grid(. ~ nivel_educativo)
```

```{r}


```

