---
title: "Regresión Lineal Simple: Evaluación y Diagnóstico"
author: "Juan Barriola y Sofía Perini"
date: "26 de Septiembre de 2020"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>


**Encuesta de Sueldos en el sector IT**

## Planteo del problema

Vamos a continuar trabajando con el dataset de la encuesta de sueldos en el sector de tecnología en Argenina realizada por SysArmy. El informe, realizado por OpenQube lo pueden ver [acá](https://sueldos.openqube.io/encuesta-sueldos-2020.01/).

El objetivo es crear un modelo lineal simple para explicar el sueldo neto de los Data Analysts, Data Scientists y Data Engineers en Argentina.

La idea subyacente de cómo se puede explicar el salario neto es:

$salarioNeto = \beta_0 +\beta_1X+\epsilon$

## Dataset y Modelos

```{r, message=FALSE}
# Carga de librerías
library(tidyverse)
library(tidymodels)
```

En el notebook previo realizamos un análisis extenso de nuestro dataset, limpieza de los datos y algunos modelos para explicar el salario.

```{r}
# Cargamos el dataset limpio
encuesta_sueldos = read_csv("~/Fuentes/encuesta_sueldos_it_limpia.csv")
```

Habíamos realizado tres modelos distintos para tratar de explicar el salario neto

  * **Modelo Edad**

  * **Modelo Años de experiencia**

  * **Modelo Años en la Empresa Actual**
  
Volvemos a realizar estos modelos:

```{r}
# Modelo Edad
modelo_edad = lm(formula = salario_neto ~ edad, data = encuesta_sueldos)
# Modelo experiencia
modelo_experiencia = lm(formula = salario_neto ~ anos_de_experiencia, data = encuesta_sueldos)
# Modelo empresa
modelo_empresa = lm(formula = salario_neto ~ anos_en_la_empresa_actual, data = encuesta_sueldos)
```

En el notebook previo sólo habíamos interpretado el valor de los parámetros estimados. Ahora buscaremos responder preguntas tales como:

  * ¿La relación entre la variable dependiente e independiente es estadísticamente significativa?
  * ¿Qué proporción de la variabilidad logra explicar el modelo? ¿Cómo decidir que modelo explica mejor el fenómeno?
  * ¿El modelo cumple con los supuestos del modelo lineal?

## Tidymodels: Broom

[Tidymodels](https://www.tidymodels.org/) es un meta-paquete (al igual que `tidyverse`) que contiene varios paquetes muy útiles para crear un framework para trabajar con modelos.

El paquete [broom](https://broom.tidymodels.org/) permite acceder a información de modelos e interactuar con los mismos de una manera sencilla. Las tres funciones para interactuar con los modelos son:

  * `tidy()`: resume información sobre los componentes del modelo
  * `glance()`: reporta información sobre todo el modelo
  * `augment()`: agrega información de las observaciones según el modelo al dataset
  
Veremos cómo utilizar estas funciones con un modelo lineal

## Evaluación del modelo

La función `summary()` nos permite obtener mucha información sobre el modelo lineal:

```{r}
resumen_modelo_edad = summary(modelo_edad)
resumen_modelo_edad
```

Observamos que hay información sobre:

  * Inferencia de $\beta_0$ y $\beta_1$
  * Estimación de $\sigma^2$
  * El coeficiente $R^2$
  * Los residuos del modelo
  
En las secciones subsiguientes vamos a desarrollar cada uno de estos aspectos

### Inferencia de $\beta_1$ (test de significatividad individual)

En la salida de `summary()`, en la parte de **coefficients** observamos que están las columnas: estimate, std error, t value y Pr(>|t|).
En las filas se encuentra el intercepto y la variable independiente: **edad**.

En el notebook anterior trabajamos sobre la interpretación del coeficiente estimado (estimate). Ahora nos focalizaremos en la columnas t value y Pr(>|t|).

En la inferencia de $\beta_1$ nos interesa responder si la relación entre la variable independiente y la variable a explicar es estadísticamente significativa. Nuestro test de hipótesis es:

$H_0 : \beta_1 = 0$

$H_1 : \beta_1 \neq 0$

El valor de **t value** nos indica el valor del estadístico T para este test.

El valor de **Pr(>|t|)** nos indica el p-valor para dicho test, acompañado de una ayuda visual sobre los niveles de significancia.

Como el p-valor es extremadamente pequeño concluimos que se rechaza la hipótesis nula, es decir, $\beta_1$ (parámetro poblacional) es distinto de cero.

Este test también se conoce como **test de significatividad individual** del parámetro. 

#### Broom: tidy

Con la función `tidy()` del paquete broom podemos obtener la información sobre los parámetros como un dataframe: 

```{r}
tidy(modelo_edad)
```

Veamos los resultados para los otros dos modelos

**Modelo Años de experiencia**

```{r}
tidy(modelo_experiencia)
```

**Modelo Años en la Empresa Actual**

```{r}
tidy(modelo_empresa)
```

En ambos modelos observamos que el p-valor asociado al test de significatividad individual de $\beta_1$ es extremadamente pequeño. Por lo tanto, concluimos que se rechaza la hipótesis nula, es decir, $\beta_1$ (parámetro poblacional) es distinto de cero. 

### Test F (test de significatividad global)

```{r}
resumen_modelo_edad
```

### Coeficiente de determinación $R^2$

El $R^2$ permite medir el porcentaje de variabilidad del fenómeno que el modelo logra explicar.  

```{r}
resumen_modelo_edad
```

El valor de $R^2$ es `r resumen_modelo_edad$r.squared`

#### Broom: glance

Con la función `glance()` del paquete broom podemos obtener la información sobre la evaluación global del modelo como un dataframe: 

```{r}
glance(modelo_edad)
```

Veamos los resultados para los otros dos modelos

**Modelo Años de experiencia**

```{r}
glance(modelo_experiencia)
```

**Modelo Años en la Empresa Actual**

```{r}
glance(modelo_empresa)
```

## Diagnóstico del modelo


```{r  out.width = "50%", fig.asp = 1, fig.width = 5, fig.align='default'}
plot(modelo_edad)
```


Estos gráficos son:

- Residuos versus el modelo ajustado:  El objetivo es que no veamos una estructura clara. Si así la hubiera, esto implicaría que hay una parte __sistemática__ del fenómeno que se esta perdiendo. 
- Normal QQ plot: sirve para ver si los datos siguen una distribución teórica, en este caso, la $\sim N(0,1)$. Los residuos estandarizados, si el modelo esta bien definido, deberían seguir esta distribución
- Scale-location plot: Similar al primer gráfico, pero utilizando la raíz cuadrada de los residuos estandarizados. De la misma forma que el anterior, buscamos que no haya una estructura en los residuos.
- residual vs leverage: El leverage mide cuan influyentes son los puntos en el modelo. Si en este gráfico algunas observaciones aparecen muy separadas, con mucho leverage y residuo, significa que cambian mucho al modelo.


```{r}
au = augment(modelo_edad, encuesta_sueldos)
au
```

```{r  message= FALSE, out.width = "50%", fig.asp = 1, fig.width = 6, fig.align='default'}

ggplot(au, aes(.fitted, .resid)) +
  geom_point()+
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw()

ggplot(au, aes(sample= .std.resid))+
  stat_qq()+
  geom_abline() +
  theme_bw()

ggplot(au, aes(.fitted, sqrt(abs(.std.resid))))+
  geom_point()+
  geom_smooth(se = FALSE) +
  theme_bw()

ggplot(au, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + geom_smooth(se = FALSE) +
  theme_bw()

```


